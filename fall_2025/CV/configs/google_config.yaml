# Configuration for Gesture Recognition Training

# Wandb settings
wandb:
  project: "gesture-recognition"
  entity: null  # Set your wandb entity/team name here or via env
  name: STGCN_conv1d  # Run name (auto-generated if null)
  tags: ["stgcn", "islr"]
  notes: "Training STGCN on google ISLR dataset"
  mode: "online"  # "online", "offline", or "disabled"

# Data settings
data:
  gloss_mapping_file: "data/google_gloss_map.csv" # The glosses to use
  metadata_file: "$SCRATCH/gesture/data/asl-signs/train.csv"
  cache_dir: "$SCRATCH/gesture/google-data/unfied_shoulder_centered"
  data_root: "$SCRATCH/gesture/data/asl-signs"
  coordinate_system: "shoulder_centered"  # "original" or "shoulder_centered"
  min_frames: 0
  max_frames: 300
  train_split: 0.8
  random_seed: 42
  body_parts: ["pose", "left_hand", "right_hand"]

# DataLoader settings
dataloader:
  batch_size: 32
  num_workers: 20
  shuffle_train: true
  pin_memory: true

# Model settings
model:
  name: "STGCN (conv1d)"
  # Model architecture will be auto-detected from data
  num_blocks: 4
  channels: 64
  spatial_channels: 16
  kernel_size: 3
  mlp_hidden: [1024, 1024, 256]
  dropout: 0.5

# Training settings
training:
  num_epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: "adamw"  # "adam", "adamw", "sgd"
  scheduler: "cosine"  # "cosine", "step", "plateau", or null
  grad_clip: 1.0  # Max norm for gradient clipping (null to disable)

  # Scheduler-specific settings
  scheduler_config:
    step_size: 10  # for StepLR
    gamma: 0.1  # for StepLR
    patience: 5  # for ReduceLROnPlateau
    min_lr: 1.0e-6  # for cosine annealing

  # Checkpointing
  checkpoint_dir: "$SCRATCH/gesture/checkpoints"
  save_best_only: true
  save_frequency: 10  # Save every N epochs

  #load 
  pretrained_checkpoint: ""

# Device settings
device: "cuda"  # "cuda", "cpu", or "auto"
